{
  "model" : "gemini-3-flash-preview",
  "messages" : [ {
    "role" : "system",
    "content" : "You are an expert software engineer. Your task is to extract a concise coding style guide from the provided code examples."
  }, {
    "role" : "user",
    "content" : "Based on these code examples, create a concise, clear coding style guide in Markdown format\nthat captures the conventions used in this codebase, particularly the ones that leverage new or uncommon features.\nDO NOT repeat what are simply common best practices.\n\n<file path=\"frontend\\index.html\">\n<!doctype html>\r\n<html lang=\"en\">\r\n\r\n<head>\r\n  <meta charset=\"UTF-8\" />\r\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\r\n  <link rel=\"icon\" type=\"image/svg+xml\" href=\"/logo-icon.svg\" />\r\n  <title>Nendo TikTok Bot | Intelligence Platform</title>\r\n  <meta name=\"description\" content=\"Nendo TikTok Social Listening & Intelligence Platform\" />\r\n  <meta name=\"author\" content=\"Nendo\" />\r\n\r\n  <meta property=\"og:title\" content=\"Nendo TikTok Bot\" />\r\n  <meta property=\"og:description\" content=\"Nendo TikTok Social Listening & Intelligence Platform\" />\r\n  <meta property=\"og:type\" content=\"website\" />\r\n\r\n  <meta name=\"twitter:card\" content=\"summary_large_image\" />\r\n  <meta name=\"twitter:site\" content=\"@Nendo\" />\r\n</head>\r\n\r\n<body>\r\n  <div id=\"root\"></div>\r\n  <script type=\"module\" src=\"/src/main.tsx\"></script>\r\n</body>\r\n\r\n</html>\n</file>\n<file path=\"frontend\\src\\components\\dashboard\\Sidebar.tsx\">\nimport { useState } from 'react';\r\nimport { cn } from '@/lib/utils';\r\nimport {\r\n  LayoutDashboard,\r\n  Search,\r\n  TrendingUp,\r\n  Users,\r\n  Hash,\r\n  MessageSquare,\r\n  Settings,\r\n  ChevronLeft,\r\n  ChevronRight,\r\n  Zap,\r\n} from 'lucide-react';\r\nimport { Button } from '@/components/ui/button';\r\n\r\ninterface NavItem {\r\n  icon: React.ElementType;\r\n  label: string;\r\n  active?: boolean;\r\n}\r\n\r\nconst navItems: { icon: any, label: string }[] = [\r\n  { icon: LayoutDashboard, label: 'Dashboard' },\r\n  { icon: Settings, label: 'Settings' },\r\n];\r\n\r\ninterface SidebarProps {\r\n  currentView: string;\r\n  onNavigate: (view: string) => void;\r\n}\r\n\r\nexport const Sidebar = ({ currentView, onNavigate }: SidebarProps) => {\r\n  const [collapsed, setCollapsed] = useState(false);\r\n\r\n  return (\r\n    <aside\r\n      className={cn(\r\n        'flex flex-col h-screen bg-sidebar border-r border-sidebar-border transition-all duration-300',\r\n        collapsed ? 'w-20' : 'w-64'\r\n      )}\r\n    >\r\n      <div\r\n        onClick={() => onNavigate('Dashboard')}\r\n        className=\"flex items-center gap-3 p-6 border-b border-sidebar-border cursor-pointer group\"\r\n      >\r\n        <div className=\"flex items-center justify-center transition-transform group-hover:scale-110 duration-300 w-10 h-10 text-primary\">\r\n          <img\r\n            src=\"/logo-icon.svg\"\r\n            alt=\"Nendo\"\r\n            className=\"w-full h-full\"\r\n          />\r\n        </div>\r\n        {!collapsed && (\r\n          <div className=\"flex flex-col\">\r\n            <span className=\"font-bold text-foreground tracking-tighter text-lg leading-none\">NENDO</span>\r\n            <span className=\"text-[10px] text-primary font-bold uppercase tracking-widest opacity-80\">Intelligence</span>\r\n          </div>\r\n        )}\r\n      </div>\r\n\r\n      {/* Navigation */}\r\n      <nav className=\"flex-1 p-4 space-y-2\">\r\n        {navItems.map((item) => (\r\n          <button\r\n            key={item.label}\r\n            onClick={() => onNavigate(item.label)}\r\n            className={cn(\r\n              'flex items-center gap-3 w-full px-4 py-3 rounded-lg transition-all duration-200',\r\n              currentView === item.label\r\n                ? 'bg-sidebar-accent text-sidebar-primary'\r\n                : 'text-sidebar-foreground hover:bg-sidebar-accent hover:text-foreground'\r\n            )}\r\n          >\r\n            <item.icon className={cn('w-5 h-5', currentView === item.label && 'text-primary')} />\r\n            {!collapsed && <span className=\"font-medium\">{item.label}</span>}\r\n          </button>\r\n        ))}\r\n      </nav>\r\n\r\n      {/* Collapse Toggle Only */}\r\n      <div className=\"p-4 border-t border-sidebar-border\">\r\n        <Button\r\n          variant=\"ghost\"\r\n          size=\"icon\"\r\n          onClick={() => setCollapsed(!collapsed)}\r\n          className=\"w-full text-muted-foreground hover:text-foreground\"\r\n        >\r\n          {collapsed ? (\r\n            <ChevronRight className=\"w-5 h-5\" />\r\n          ) : (\r\n            <ChevronLeft className=\"w-5 h-5\" />\r\n          )}\r\n        </Button>\r\n      </div>\r\n    </aside>\r\n  );\r\n};\n</file>\n<file path=\"frontend\\vite.config.ts\">\nimport { defineConfig } from \"vite\";\r\nimport react from \"@vitejs/plugin-react-swc\";\r\nimport path from \"path\";\r\n\r\n// https://vitejs.dev/config/\r\nexport default defineConfig(({ mode }) => ({\r\n  server: {\r\n    host: \"::\",\r\n    port: 8081,\r\n    hmr: {\r\n      overlay: false,\r\n    },\r\n  },\r\n  plugins: [react()],\r\n  resolve: {\r\n    alias: {\r\n      \"@\": path.resolve(__dirname, \"./src\"),\r\n    },\r\n  },\r\n}));\r\n\n</file>\n<file path=\"frontend\\README.md\">\n# Nendo TikTok Bot - Frontend\r\n\r\nThis is the curated React frontend for the Nendo TikTok Intelligence Platform.\r\n\r\n## üöÄ Getting Started\r\n\r\n### Prerequisites\r\n- Node.js (v18+)\r\n- npm or bun\r\n\r\n### Installation\r\n1. Navigate to the frontend directory:\r\n   ```bash\r\n   cd frontend\r\n   ```\r\n2. Install dependencies:\r\n   ```bash\r\n   npm install\r\n   ```\r\n3. Start the development server:\r\n   ```bash\r\n   npm run dev\r\n   ```\r\n\r\n## üõ†Ô∏è Tech Stack\r\n- **Vite**: Next-generation frontend tooling\r\n- **TypeScript**: Static typing for JavaScript\r\n- **React**: UI library\r\n- **Shadcn UI**: Beautifully designed components\r\n- **Tailwind CSS**: Utility-first CSS framework\r\n- **Recharts**: Composant charting library\r\n- **Lucide React**: Clean icons\r\n\r\n## üìä Features\r\n- Live scraping controls\r\n- Interactive sentiment pie charts\r\n- Engagement timeline with activity peaks\r\n- Detailed content log with direct TikTok links\r\n- Filterable video gallery\r\n\r\n## üåê Deployment\r\nThis project is configured for deployment on **Vercel**. Simply connect your GitHub repository and ensure the build settings are:\r\n- **Build Command**: `npm run build`\r\n- **Output Directory**: `dist`\r\n- **Root Directory**: `frontend`\r\n\n</file>\n<file path=\"frontend\\package.json\">\n{\r\n  \"name\": \"vite_react_shadcn_ts\",\r\n  \"private\": true,\r\n  \"version\": \"0.0.0\",\r\n  \"type\": \"module\",\r\n  \"scripts\": {\r\n    \"dev\": \"vite\",\r\n    \"build\": \"vite build\",\r\n    \"build:dev\": \"vite build --mode development\",\r\n    \"lint\": \"eslint .\",\r\n    \"preview\": \"vite preview\",\r\n    \"test\": \"vitest run\",\r\n    \"test:watch\": \"vitest\"\r\n  },\r\n  \"dependencies\": {\r\n    \"@hookform/resolvers\": \"^3.10.0\",\r\n    \"@radix-ui/react-accordion\": \"^1.2.11\",\r\n    \"@radix-ui/react-alert-dialog\": \"^1.1.14\",\r\n    \"@radix-ui/react-aspect-ratio\": \"^1.1.7\",\r\n    \"@radix-ui/react-avatar\": \"^1.1.10\",\r\n    \"@radix-ui/react-checkbox\": \"^1.3.2\",\r\n    \"@radix-ui/react-collapsible\": \"^1.1.11\",\r\n    \"@radix-ui/react-context-menu\": \"^2.2.15\",\r\n    \"@radix-ui/react-dialog\": \"^1.1.14\",\r\n    \"@radix-ui/react-dropdown-menu\": \"^2.1.15\",\r\n    \"@radix-ui/react-hover-card\": \"^1.1.14\",\r\n    \"@radix-ui/react-label\": \"^2.1.7\",\r\n    \"@radix-ui/react-menubar\": \"^1.1.15\",\r\n    \"@radix-ui/react-navigation-menu\": \"^1.2.13\",\r\n    \"@radix-ui/react-popover\": \"^1.1.14\",\r\n    \"@radix-ui/react-progress\": \"^1.1.7\",\r\n    \"@radix-ui/react-radio-group\": \"^1.3.7\",\r\n    \"@radix-ui/react-scroll-area\": \"^1.2.9\",\r\n    \"@radix-ui/react-select\": \"^2.2.5\",\r\n    \"@radix-ui/react-separator\": \"^1.1.7\",\r\n    \"@radix-ui/react-slider\": \"^1.3.5\",\r\n    \"@radix-ui/react-slot\": \"^1.2.3\",\r\n    \"@radix-ui/react-switch\": \"^1.2.5\",\r\n    \"@radix-ui/react-tabs\": \"^1.1.12\",\r\n    \"@radix-ui/react-toast\": \"^1.2.14\",\r\n    \"@radix-ui/react-toggle\": \"^1.1.9\",\r\n    \"@radix-ui/react-toggle-group\": \"^1.1.10\",\r\n    \"@radix-ui/react-tooltip\": \"^1.2.7\",\r\n    \"@tanstack/react-query\": \"^5.83.0\",\r\n    \"class-variance-authority\": \"^0.7.1\",\r\n    \"clsx\": \"^2.1.1\",\r\n    \"cmdk\": \"^1.1.1\",\r\n    \"date-fns\": \"^3.6.0\",\r\n    \"embla-carousel-react\": \"^8.6.0\",\r\n    \"input-otp\": \"^1.4.2\",\r\n    \"lucide-react\": \"^0.462.0\",\r\n    \"next-themes\": \"^0.3.0\",\r\n    \"react\": \"^18.3.1\",\r\n    \"react-day-picker\": \"^8.10.1\",\r\n    \"react-dom\": \"^18.3.1\",\r\n    \"react-hook-form\": \"^7.61.1\",\r\n    \"react-resizable-panels\": \"^2.1.9\",\r\n    \"react-router-dom\": \"^6.30.1\",\r\n    \"recharts\": \"^2.15.4\",\r\n    \"sonner\": \"^1.7.4\",\r\n    \"tailwind-merge\": \"^2.6.0\",\r\n    \"tailwindcss-animate\": \"^1.0.7\",\r\n    \"vaul\": \"^0.9.9\",\r\n    \"zod\": \"^3.25.76\"\r\n  },\r\n  \"devDependencies\": {\r\n    \"@eslint/js\": \"^9.32.0\",\r\n    \"@testing-library/jest-dom\": \"^6.6.0\",\r\n    \"@testing-library/react\": \"^16.0.0\",\r\n    \"@tailwindcss/typography\": \"^0.5.16\",\r\n    \"@types/node\": \"^22.16.5\",\r\n    \"@types/react\": \"^18.3.23\",\r\n    \"@types/react-dom\": \"^18.3.7\",\r\n    \"@vitejs/plugin-react-swc\": \"^3.11.0\",\r\n    \"autoprefixer\": \"^10.4.21\",\r\n    \"eslint\": \"^9.32.0\",\r\n    \"eslint-plugin-react-hooks\": \"^5.2.0\",\r\n    \"eslint-plugin-react-refresh\": \"^0.4.20\",\r\n    \"globals\": \"^15.15.0\",\r\n    \"jsdom\": \"^20.0.3\",\r\n    \"postcss\": \"^8.5.6\",\r\n    \"tailwindcss\": \"^3.4.17\",\r\n    \"typescript\": \"^5.8.3\",\r\n    \"typescript-eslint\": \"^8.38.0\",\r\n    \"vite\": \"^5.4.19\",\r\n    \"vitest\": \"^3.2.4\"\r\n  }\r\n}\n</file>\n<file path=\".gitignore\">\n# Python\r\n__pycache__/\r\n*.py[cod]\r\n*$py.class\r\n*.so\r\n.Python\r\nbuild/\r\ndevelop-eggs/\r\ndist/\r\ndownloads/\r\neggs/\r\n.eggs/\r\nlib/\r\nlib64/\r\nparts/\r\nsdist/\r\nvar/\r\nwheels/\r\nshare/python-wheels/\r\n*.egg-info/\r\n.installed.cfg\r\n*.egg\r\nMANIFEST\r\n\r\n# Virtual Environment\r\nvenv/\r\nenv/\r\nENV/\r\n.env\r\n\r\n# Secrets\r\ncredentials.json\r\nsecrets.json\r\nclient_secret.json\r\n\r\n# Streamlit\r\n.streamlit/\r\n\r\n# Node\r\nnode_modules/\r\nfrontend/node_modules/\r\nfrontend/dist/\r\n\r\n# Local Data\r\ndata_cache.json\r\nconfig.json\r\n\r\n# OS\r\n.DS_Store\r\nThumbs.db\r\n\n</file>\n<file path=\"scraper.py\">\n\"\"\"\r\nTikTok scraper module using Apify Actor (clockworks/tiktok-scraper)\r\n\"\"\"\r\nfrom apify_client import ApifyClient\r\nimport asyncio\r\nfrom datetime import datetime\r\nimport os\r\nimport re\r\n\r\n\r\nclass TikTokScraper:\r\n    def __init__(self, api_token=None):\r\n        \"\"\"\r\n        Initialize Apify scraper\r\n        \r\n        Args:\r\n            api_token: Apify API token. If None, looks for APIFY_API_TOKEN env var.\r\n        \"\"\"\r\n        self.token = api_token or os.getenv('APIFY_API_TOKEN')\r\n        if not self.token:\r\n            print(\"‚ö†Ô∏è No Apify API token provided. Scraper will fail unless token is passed.\")\r\n            self.client = None\r\n        else:\r\n            self.client = ApifyClient(self.token)\r\n        \r\n        # Using clockworks/tiktok-scraper as it is reliable\r\n        self.actor_id = \"clockworks/tiktok-scraper\"\r\n\r\n    async def initialize(self):\r\n        \"\"\"Check connection - lightweight for Apify\"\"\"\r\n        if not self.client and self.token:\r\n            self.client = ApifyClient(self.token)\r\n        return True if self.client else False\r\n    \r\n    def extract_hashtags(self, caption):\r\n        \"\"\"Helper to extract hashtags from caption\"\"\"\r\n        if not caption: return \"\"\r\n        return ', '.join(re.findall(r'#(\\w+)', caption))\r\n\r\n    def extract_mentions(self, caption):\r\n        \"\"\"Helper to extract mentions from caption\"\"\"\r\n        if not caption: return \"\"\r\n        return ', '.join(re.findall(r'@(\\w+)', caption))\r\n\r\n    def _map_result(self, item, extract_comments=False):\r\n        \"\"\"Map Apify result to our app's data structure\"\"\"\r\n        try:\r\n            # Video Date\r\n            video_date = datetime.now()\r\n            if 'createTime' in item:\r\n                try: video_date = datetime.fromtimestamp(item['createTime'])\r\n                except: pass\r\n            elif 'createTimeISO' in item:\r\n                try: video_date = datetime.fromisoformat(item['createTimeISO'].replace('Z', '+00:00'))\r\n                except: pass\r\n\r\n            video_data = {\r\n                'video_id': item.get('id', item.get('videoMeta', {}).get('id', '')),\r\n                'video_url': item.get('webVideoUrl', ''),\r\n                'caption': item.get('text', ''),\r\n                'author': item.get('authorMeta', {}).get('name', ''),\r\n                'likes': item.get('diggCount', 0),\r\n                'comments': item.get('commentCount', 0),\r\n                'shares': item.get('shareCount', 0),\r\n                'saves': item.get('collectCount', 0),\r\n                'views': item.get('playCount', 0),\r\n                'publish_date': video_date.strftime('%Y-%m-%d %H:%M:%S'),\r\n                'hashtags': ', '.join([t.get('name', '') for t in item.get('hashtags', [])]) or self.extract_hashtags(item.get('text', '')),\r\n                'mentions': self.extract_mentions(item.get('text', '')),\r\n                'thumbnail_url': item.get('coverUrl', item.get('videoMeta', {}).get('coverUrl', ''))\r\n            }\r\n\r\n            if extract_comments:\r\n                comments_list = []\r\n                # clockworks/tiktok-scraper usually returns comments in 'comments' list if requested\r\n                raw_comments = item.get('comments', [])\r\n                for c in raw_comments:\r\n                    try:\r\n                        c_date = datetime.now()\r\n                        if 'createTime' in c:\r\n                             try: c_date = datetime.fromtimestamp(c['createTime'])\r\n                             except: pass\r\n                        \r\n                        comments_list.append({\r\n                            'comment_id': c.get('id', ''),\r\n                            'video_id': video_data['video_id'],\r\n                            'text': c.get('text', ''),\r\n                            'author': c.get('authorUniqueId', ''),\r\n                            'date': c_date.strftime('%Y-%m-%d %H:%M:%S'),\r\n                            'likes': c.get('diggCount', 0)\r\n                        })\r\n                    except: continue\r\n                video_data['scraped_comments'] = comments_list\r\n\r\n            return video_data\r\n        except Exception as e:\r\n            print(f\"Error mapping item: {e}\")\r\n            return None\r\n\r\n    async def _run_actor(self, run_input, limit=None, since_date=None, comments_per_video=0):\r\n        \"\"\"Generic actor runner with limits\"\"\"\r\n        if not self.client:\r\n            print(\"‚ùå Apify Client not initialized. Missing API Token.\")\r\n            return []\r\n        \r\n        print(f\"üöÄ Starting Apify Actor: {self.actor_id} with input: {run_input}\")\r\n        \r\n        results = []\r\n        try:\r\n            run = self.client.actor(self.actor_id).call(run_input=run_input)\r\n            \r\n            dataset_id = run.get('defaultDatasetId')\r\n            if not dataset_id:\r\n                return []\r\n            \r\n            print(f\"‚úÖ Run finished. Fetching results from dataset {dataset_id}...\")\r\n            \r\n            dataset_items = self.client.dataset(dataset_id).iterate_items()\r\n            \r\n            count = 0\r\n            for item in dataset_items:\r\n                # Map result (extract comments if requested)\r\n                mapped = self._map_result(item, extract_comments=(comments_per_video > 0))\r\n                if not mapped: continue\r\n                \r\n                # Check limits\r\n                if since_date:\r\n                    item_date = datetime.strptime(mapped['publish_date'], '%Y-%m-%d %H:%M:%S')\r\n                    if item_date < since_date:\r\n                        continue \r\n                \r\n                results.append(mapped)\r\n                count += 1\r\n                \r\n                if limit and count >= limit:\r\n                    break\r\n            \r\n            return results\r\n            \r\n        except Exception as e:\r\n            print(f\"‚ùå Error running Apify actor: {e}\")\r\n            return []\r\n\r\n    async def scrape_hashtag(self, hashtags, count=None, since_date=None, comments_per_video=0):\r\n        if isinstance(hashtags, str):\r\n            hashtags = [h.strip() for h in hashtags.split(',')]\r\n            \r\n        limit = count if count else 100\r\n        run_input = {\r\n            \"hashtags\": hashtags,\r\n            \"resultsPerPage\": limit,\r\n            \"shouldDownloadVideos\": False,\r\n            \"commentsPerVideo\": comments_per_video\r\n        }\r\n        return await self._run_actor(run_input, limit, since_date, comments_per_video)\r\n\r\n    async def scrape_user(self, usernames, count=None, since_date=None, comments_per_video=0):\r\n        if isinstance(usernames, str):\r\n            usernames = [u.strip() for u in usernames.split(',')]\r\n            \r\n        limit = count if count else 100\r\n        run_input = {\r\n            \"profiles\": usernames,\r\n            \"resultsPerPage\": limit,\r\n            \"shouldDownloadVideos\": False,\r\n            \"commentsPerVideo\": comments_per_video\r\n        }\r\n        return await self._run_actor(run_input, limit, since_date, comments_per_video)\r\n\r\n    async def scrape_search(self, queries, count=None, since_date=None, comments_per_video=0):\r\n        if isinstance(queries, str):\r\n            queries = [q.strip() for q in queries.split(',')]\r\n        \r\n        limit = count if count else 100\r\n        run_input = {\r\n            \"searchQueries\": queries,\r\n            \"resultsPerPage\": limit,\r\n            \"shouldDownloadVideos\": False,\r\n            \"commentsPerVideo\": comments_per_video\r\n        }\r\n        return await self._run_actor(run_input, limit, since_date, comments_per_video)\r\n\r\n    async def close(self):\r\n        pass\r\n\r\n\r\n# Synchronous wrappers\r\ndef scrape_hashtag_sync(hashtags, count=None, since_date=None, api_token=None, comments_per_video=0):\r\n    scraper = TikTokScraper(api_token)\r\n    return asyncio.run(scraper.scrape_hashtag(hashtags, count, since_date, comments_per_video))\r\n\r\ndef scrape_user_sync(usernames, count=None, since_date=None, api_token=None, comments_per_video=0):\r\n    scraper = TikTokScraper(api_token)\r\n    return asyncio.run(scraper.scrape_user(usernames, count, since_date, comments_per_video))\r\n\r\ndef scrape_search_sync(queries, count=None, since_date=None, api_token=None, comments_per_video=0):\r\n    scraper = TikTokScraper(api_token)\r\n    return asyncio.run(scraper.scrape_search(queries, count, since_date, comments_per_video))\r\n\n</file>\n<file path=\"sheets.py\">\n\"\"\"\r\nGoogle Sheets integration module for storing TikTok data\r\n\"\"\"\r\nimport gspread\r\nfrom oauth2client.service_account import ServiceAccountCredentials\r\nimport pandas as pd\r\nfrom datetime import datetime\r\nimport os\r\n\r\n\r\nclass SheetsManager:\r\n    def __init__(self, credentials_file='credentials.json', sheet_name='TikTok Analytics', sheet_url='https://docs.google.com/spreadsheets/d/1dirtUrGwr-r3sfpocamL1N8xkwJEk1xn8lcMfrU_bI0/edit?usp=sharing'):\r\n        \"\"\"\r\n        Initialize Google Sheets connection\r\n        \r\n        Args:\r\n            credentials_file: Path to Google service account credentials JSON\r\n            sheet_name: Name of the Google Sheet to use (fallback)\r\n            sheet_url: Direct URL to the Google Sheet (preferred)\r\n        \"\"\"\r\n        self.sheet_name = sheet_name\r\n        self.sheet_url = sheet_url\r\n        self.credentials_file = credentials_file\r\n        self.client = None\r\n        self.sheet = None\r\n        self.worksheet = None\r\n        \r\n    def connect(self):\r\n        \"\"\"Establish connection to Google Sheets\"\"\"\r\n        try:\r\n            scope = [\r\n                'https://spreadsheets.google.com/feeds',\r\n                'https://www.googleapis.com/auth/drive'\r\n            ]\r\n            \r\n            if not os.path.exists(self.credentials_file):\r\n                print(f\"‚ö†Ô∏è Credentials file not found: {self.credentials_file}\")\r\n                return False\r\n            \r\n            creds = ServiceAccountCredentials.from_json_keyfile_name(\r\n                self.credentials_file, scope\r\n            )\r\n            self.client = gspread.authorize(creds)\r\n            \r\n            # Try to open by URL first (most reliable), then by name\r\n            try:\r\n                if self.sheet_url:\r\n                    print(f\"üîó Opening sheet by URL: {self.sheet_url}\")\r\n                    self.sheet = self.client.open_by_url(self.sheet_url)\r\n                else:\r\n                    self.sheet = self.client.open(self.sheet_name)\r\n            except gspread.SpreadsheetNotFound:\r\n                if self.sheet_url:\r\n                     print(f\"‚ùå Could not find sheet with URL. Checking by name...\")\r\n                \r\n                try:\r\n                    self.sheet = self.client.open(self.sheet_name)\r\n                except gspread.SpreadsheetNotFound:\r\n                    print(f\"Creating new spreadsheet: {self.sheet_name}\")\r\n                    self.sheet = self.client.create(self.sheet_name)\r\n                    self.sheet.share('', perm_type='anyone', role='reader')\r\n            \r\n            # Get or create worksheet (Videos)\r\n            try:\r\n                self.worksheet = self.sheet.sheet1\r\n                if self.worksheet.title.lower() != 'data':\r\n                     try: self.worksheet.update_title('Videos')\r\n                     except: pass\r\n            except:\r\n                self.worksheet = self.sheet.add_worksheet(title=\"Videos\", rows=\"1000\", cols=\"20\")\r\n            \r\n            # Initialize headers if empty\r\n            if not self.worksheet.row_values(1):\r\n                headers = [\r\n                    'timestamp', 'video_id', 'video_url', 'caption', 'author',\r\n                    'likes', 'comments', 'shares', 'saves', 'views', 'publish_date',\r\n                    'hashtags', 'mentions', 'thumbnail_url'\r\n                ]\r\n                self.worksheet.append_row(headers)\r\n\r\n            # Get or create Comments worksheet\r\n            try:\r\n                self.comments_sheet = self.sheet.worksheet(\"Comments\")\r\n            except:\r\n                self.comments_sheet = self.sheet.add_worksheet(title=\"Comments\", rows=\"1000\", cols=\"8\")\r\n                # Headers for comments\r\n                self.comments_sheet.append_row([\r\n                    'scraped_at', 'video_id', 'comment_id', 'author', \r\n                    'text', 'likes', 'date'\r\n                ])\r\n            \r\n            print(f\"‚úÖ Connected to Google Sheets: {self.sheet_name}\")\r\n            return True\r\n            \r\n        except Exception as e:\r\n            print(f\"‚ùå Error connecting to Google Sheets: {e}\")\r\n            return False\r\n    \r\n    def get_existing_video_ids(self):\r\n        \"\"\"Get list of existing video IDs to avoid duplicates\"\"\"\r\n        try:\r\n            if not self.worksheet:\r\n                return set()\r\n            video_ids = self.worksheet.col_values(2)[1:]  # Skip header\r\n            return set(video_ids)\r\n        except Exception as e:\r\n            print(f\"Error getting existing video IDs: {e}\")\r\n            return set()\r\n    \r\n    def append_comments(self, comments_list):\r\n        \"\"\"\r\n        Append comments to the separate Comments sheet\r\n        \"\"\"\r\n        if not self.comments_sheet or not comments_list:\r\n            return 0\r\n        \r\n        try:\r\n            # We don't check for duplicate comments strictly here to save API calls/time, \r\n            # but ideally we would. For now, just append.\r\n            # Convert list of dicts to list of lists\r\n            rows = []\r\n            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\r\n            \r\n            for c in comments_list:\r\n                rows.append([\r\n                    timestamp,\r\n                    c.get('video_id', ''),\r\n                    c.get('comment_id', ''),\r\n                    c.get('author', ''),\r\n                    c.get('text', ''),\r\n                    c.get('likes', 0),\r\n                    c.get('date', '')\r\n                ])\r\n            \r\n            if rows:\r\n                self.comments_sheet.append_rows(rows)\r\n                print(f\"‚úÖ Added {len(rows)} comments to Sheets\")\r\n            \r\n            return len(rows)\r\n        except Exception as e:\r\n            print(f\"‚ùå Error appending comments: {e}\")\r\n            return 0\r\n\r\n    def append_data(self, data_list):\r\n        \"\"\"\r\n        Append new TikTok data to sheet, avoiding duplicates\r\n        \r\n        Args:\r\n            data_list: List of dictionaries containing TikTok video data\r\n        \r\n        Returns:\r\n            Number of new rows added\r\n        \"\"\"\r\n        if not self.worksheet:\r\n            print(\"Not connected to Google Sheets\")\r\n            return 0\r\n        \r\n        try:\r\n            existing_ids = self.get_existing_video_ids()\r\n            new_rows = 0\r\n            \r\n            for data in data_list:\r\n                video_id = str(data.get('video_id', ''))\r\n                \r\n                # Skip if already exists\r\n                if video_id in existing_ids:\r\n                    continue\r\n                \r\n                row = [\r\n                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\r\n                    video_id,\r\n                    data.get('video_url', ''),\r\n                    data.get('caption', ''),\r\n                    data.get('author', ''),\r\n                    data.get('likes', 0),\r\n                    data.get('comments', 0),\r\n                    data.get('shares', 0),\r\n                    data.get('saves', 0),\r\n                    data.get('views', 0),\r\n                    data.get('publish_date', ''),\r\n                    data.get('hashtags', ''),\r\n                    data.get('mentions', ''),\r\n                    data.get('thumbnail_url', '')\r\n                ]\r\n                \r\n                self.worksheet.append_row(row)\r\n                existing_ids.add(video_id)\r\n                new_rows += 1\r\n            \r\n            print(f\"‚úÖ Added {new_rows} new rows to Google Sheets\")\r\n            return new_rows\r\n            \r\n        except Exception as e:\r\n            print(f\"‚ùå Error appending data: {e}\")\r\n            return 0\r\n    \r\n    def get_all_data(self):\r\n        \"\"\"\r\n        Retrieve all data from sheet as pandas DataFrame\r\n        \r\n        Returns:\r\n            pandas DataFrame with all data\r\n        \"\"\"\r\n        try:\r\n            if not self.worksheet:\r\n                return pd.DataFrame()\r\n            \r\n            data = self.worksheet.get_all_records()\r\n            df = pd.DataFrame(data)\r\n            \r\n            # Convert numeric columns\r\n            numeric_cols = ['likes', 'comments', 'shares', 'saves', 'views']\r\n            for col in numeric_cols:\r\n                if col in df.columns:\r\n                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\r\n            \r\n            # Convert date columns\r\n            if 'publish_date' in df.columns:\r\n                df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')\r\n            if 'timestamp' in df.columns:\r\n                df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\r\n            \r\n            return df\r\n            \r\n        except Exception as e:\r\n            print(f\"Error retrieving data: {e}\")\r\n            return pd.DataFrame()\r\n    def get_all_comments(self):\r\n        \"\"\"\r\n        Retrieve all comment data from the Comments sheet as pandas DataFrame\r\n        \r\n        Returns:\r\n            pandas DataFrame with all comments\r\n        \"\"\"\r\n        try:\r\n            if not self.comments_sheet:\r\n                return pd.DataFrame()\r\n            \r\n            data = self.comments_sheet.get_all_records()\r\n            df = pd.DataFrame(data)\r\n            \r\n            # Convert numeric columns\r\n            if 'likes' in df.columns:\r\n                df['likes'] = pd.to_numeric(df['likes'], errors='coerce').fillna(0)\r\n            \r\n            # Convert date columns\r\n            if 'date' in df.columns:\r\n                df['date'] = pd.to_datetime(df['date'], errors='coerce')\r\n            if 'scraped_at' in df.columns:\r\n                df['scraped_at'] = pd.to_datetime(df['scraped_at'], errors='coerce')\r\n            \r\n            return df\r\n            \r\n        except Exception as e:\r\n            print(f\"Error retrieving comments: {e}\")\r\n            return pd.DataFrame()\r\n    \r\n    def get_sheet_url(self):\r\n        \"\"\"Get the URL of the Google Sheet\"\"\"\r\n        if self.sheet:\r\n            return self.sheet.url\r\n        return None\r\n\n</file>\n<file path=\"app.py\">\n\"\"\"\r\nTikTok Social Listening & Analytics Dashboard\r\nMain Streamlit application\r\n\"\"\"\r\nimport streamlit as st\r\nimport plotly.express as px\r\nimport plotly.graph_objects as go\r\nfrom wordcloud import WordCloud\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\nfrom datetime import datetime, timedelta\r\nimport os\r\n\r\nfrom scraper import scrape_hashtag_sync, scrape_user_sync\r\nfrom analysis import TikTokAnalyzer\r\nfrom sheets import SheetsManager\r\n\r\n\r\n# Page configuration\r\nst.set_page_config(\r\n    page_title=\"TikTok Analytics Dashboard\",\r\n    page_icon=\"üìä\",\r\n    layout=\"wide\",\r\n    initial_sidebar_state=\"expanded\"\r\n)\r\n\r\n# Standard Streamlit styling (Plain)\r\nst.markdown(\"\"\"\r\n<style>\r\n    .main-header {\r\n        font-size: 2.5rem;\r\n        font-weight: 700;\r\n        margin-bottom: 0.5rem;\r\n    }\r\n</style>\r\n\"\"\", unsafe_allow_html=True)\r\n\r\n\r\n\r\n# Initialize session state\r\nif 'data_loaded' not in st.session_state:\r\n    st.session_state.data_loaded = False\r\nif 'df' not in st.session_state:\r\n    st.session_state.df = pd.DataFrame()\r\nif 'df_comments' not in st.session_state:\r\n    st.session_state.df_comments = pd.DataFrame()\r\nif 'df_comments_filtered' not in st.session_state:\r\n    st.session_state.df_comments_filtered = pd.DataFrame()\r\n\r\n\r\n@st.cache_resource\r\ndef get_sheets_manager():\r\n    \"\"\"Initialize and cache Google Sheets manager\"\"\"\r\n    manager = SheetsManager()\r\n    manager.connect()\r\n    return manager\r\n\r\n\r\n@st.cache_resource\r\ndef get_analyzer():\r\n    \"\"\"Initialize and cache analyzer\"\"\"\r\n    return TikTokAnalyzer()\r\n\r\n\r\ndef create_wordcloud(text_data):\r\n    \"\"\"Generate word cloud from text data\"\"\"\r\n    if not text_data:\r\n        return None\r\n    \r\n    wordcloud = WordCloud(\r\n        width=800,\r\n        height=400,\r\n        background_color='white',\r\n        colormap='viridis',\r\n        max_words=50\r\n    ).generate(text_data)\r\n    \r\n    fig, ax = plt.subplots(figsize=(10, 5))\r\n    ax.imshow(wordcloud, interpolation='bilinear')\r\n    ax.axis('off')\r\n    plt.tight_layout(pad=0)\r\n    \r\n    return fig\r\n\r\n\r\n\r\n def main():\r\n     # Header\r\n     st.markdown('<h1 class=\"main-header\">üìä TikTok Social Listening Dashboard</h1>', unsafe_allow_html=True)\r\n    st.markdown(\"Track hashtags, analyze sentiment, and discover insights from TikTok content\")\r\n    \r\n    # Sidebar\r\n    st.sidebar.title(\"üéØ Filters & Controls\")\r\n    \r\n    # Connection Status\r\n    if not os.path.exists(\"credentials.json\"):\r\n        st.sidebar.error(\"‚ùå Google Sheets: Disconnected\")\r\n        st.sidebar.caption(\"Missing `credentials.json`. Data will be temporary.\")\r\n    else:\r\n        st.sidebar.success(\"‚úÖ Google Sheets: File Found\")\r\n    \r\n    # Scraping controls\r\n    st.sidebar.header(\"Data Collection\")\r\n    \r\n    # Apify Token Input\r\n    apify_token = st.sidebar.text_input(\"Apify API Token\", type=\"password\", help=\"Get your token from https://console.apify.com/account/integrations\")\r\n    if not apify_token:\r\n        st.sidebar.warning(\"‚ö†Ô∏è Apify Token required\")\r\n    \r\n    scrape_type = st.sidebar.radio(\"Scrape by:\", [\"Hashtag\", \"Username\", \"Keyword/Search\"])\r\n    \r\n    if scrape_type == \"Hashtag\":\r\n        search_input = st.sidebar.text_input(\"Enter hashtag (without #)\", placeholder=\"viral\")\r\n    elif scrape_type == \"Username\":\r\n        search_input = st.sidebar.text_input(\"Enter username (without @)\", placeholder=\"username\")\r\n    else:\r\n        search_input = st.sidebar.text_input(\"Enter keyword (treated as hashtag)\", placeholder=\"tiktok analytics\")\r\n    \r\n    # Date limit for scraping\r\n    use_date_limit = st.sidebar.checkbox(\"Limit by Date (Stop if older)\")\r\n    since_date = None\r\n    if use_date_limit:\r\n        since_date_input = st.sidebar.date_input(\"Scrape videos since:\", \r\n                                                value=datetime.now().date() - timedelta(days=7),\r\n                                                max_value=datetime.now().date())\r\n        since_date = datetime.combine(since_date_input, datetime.min.time())\r\n    \r\n    # Count limit\r\n    no_limit = st.sidebar.checkbox(\"No Video Limit\")\r\n    if no_limit:\r\n        video_count = None\r\n        st.sidebar.caption(\"‚ö†Ô∏è Might consume many Apify credits.\")\r\n    else:\r\n        video_count = st.sidebar.number_input(\"Max videos to scrape\", min_value=10, max_value=10000, value=50, step=10)\r\n    \r\n    # Comments Scraping (Now for all modes)\r\n    st.sidebar.subheader(\"üí¨ Comments\")\r\n    scrape_comments = st.sidebar.checkbox(\"Scrape Comments for each video\")\r\n    comments_limit = 0\r\n    if scrape_comments:\r\n        comments_limit = st.sidebar.number_input(\"Max comments per video\", min_value=10, max_value=2000, value=50)\r\n    \r\n    if st.sidebar.button(\"üîÑ Scrape New Data\", use_container_width=True):\r\n        if not apify_token:\r\n            st.sidebar.error(\"Please enter your Apify API Token first!\")\r\n        elif search_input:\r\n            with st.spinner(f\"Running Apify Actor for '{search_input}'...\"):\r\n                try:\r\n                    # Determine scraper function\r\n                    results = []\r\n                    if scrape_type == \"Hashtag\":\r\n                        results = scrape_hashtag_sync(search_input, video_count, since_date, apify_token, comments_limit if scrape_comments else 0)\r\n                    elif scrape_type == \"Username\":\r\n                        # Pass comment limits\r\n                        results = scrape_user_sync(search_input, video_count, since_date, apify_token, comments_limit if scrape_comments else 0)\r\n                    else:\r\n                        from scraper import scrape_search_sync\r\n                        results = scrape_search_sync(search_input, video_count, since_date, apify_token, comments_limit if scrape_comments else 0)\r\n                    \r\n                    if results:\r\n                        # Extract comments if any\r\n                        all_comments = []\r\n                        for video in results:\r\n                            if 'scraped_comments' in video:\r\n                                all_comments.extend(video['scraped_comments'])\r\n                                # Remove from video dict before saving to main sheet to keep it clean\r\n                                del video['scraped_comments']\r\n\r\n                        # Save to Google Sheets\r\n                        sheets = get_sheets_manager()\r\n                        if sheets.worksheet:\r\n                            new_rows = sheets.append_data(results)\r\n                            msg = f\"‚úÖ Scraped {len(results)} videos\"\r\n                            \r\n                            if all_comments:\r\n                                new_comments = sheets.append_comments(all_comments)\r\n                                msg += f\" and {new_comments} comments\"\r\n                            \r\n                            st.sidebar.success(msg)\r\n                        else:\r\n                            st.sidebar.warning(\"‚ö†Ô∏è Google Sheets not connected. Data not saved.\")\r\n                            if st.session_state.df.empty:\r\n                                st.session_state.df = pd.DataFrame(results)\r\n                            else:\r\n                                st.session_state.df = pd.concat([st.session_state.df, pd.DataFrame(results)], ignore_index=True)\r\n                        \r\n                        # Update session state immediately so UI refreshes without manual load\r\n                        new_df = pd.DataFrame(results)\r\n                        analyzer = get_analyzer()\r\n                        new_df = analyzer.calculate_engagement_rate(new_df)\r\n                        new_df = analyzer.add_sentiment_analysis(new_df, method='vader')\r\n                        \r\n                        if st.session_state.df.empty:\r\n                            st.session_state.df = new_df\r\n                        else:\r\n                            st.session_state.df = pd.concat([st.session_state.df, new_df], ignore_index=True).drop_duplicates('video_id')\r\n                        \r\n                        if all_comments:\r\n                            new_c_df = pd.DataFrame(all_comments)\r\n                            new_c_df = analyzer.add_sentiment_analysis(new_c_df, method='vader', text_column='text')\r\n                            if st.session_state.df_comments.empty:\r\n                                st.session_state.df_comments = new_c_df\r\n                            else:\r\n                                st.session_state.df_comments = pd.concat([st.session_state.df_comments, new_c_df], ignore_index=True).drop_duplicates('comment_id')\r\n                            st.session_state.df_comments_filtered = st.session_state.df_comments\r\n                        \r\n                        st.session_state.data_loaded = True\r\n                        \r\n                    else:\r\n                        st.sidebar.error(\"No data found or Apify run failed. Check your token and credits.\")\r\n                        \r\n                except Exception as e:\r\n                    st.sidebar.error(f\"Error scraping: {str(e)}\")\r\n        else:\r\n            st.sidebar.warning(\"Please enter a search term\")\r\n    \r\n    st.sidebar.divider()\r\n    \r\n    # Load data from Google Sheets\r\n    if st.sidebar.button(\"üì• Load Data from Sheets\", use_container_width=True):\r\n        with st.spinner(\"Loading data from Google Sheets...\"):\r\n            sheets = get_sheets_manager()\r\n            df = sheets.get_all_data()\r\n            \r\n            if not df.empty:\r\n                # Add analytics\r\n                analyzer = get_analyzer()\r\n                df = analyzer.calculate_engagement_rate(df)\r\n                df = analyzer.add_sentiment_analysis(df, method='vader')\r\n                \r\n                st.session_state.df = df\r\n                \r\n                # Load comments\r\n                df_comments = sheets.get_all_comments()\r\n                if not df_comments.empty:\r\n                    df_comments = analyzer.add_sentiment_analysis(df_comments, method='vader', text_column='text')\r\n                st.session_state.df_comments = df_comments\r\n                st.session_state.df_comments_filtered = df_comments # Initialize\r\n                \r\n                st.session_state.data_loaded = True\r\n                st.sidebar.success(f\"‚úÖ Loaded {len(df)} videos and {len(df_comments)} comments\")\r\n            else:\r\n                st.sidebar.warning(\"No data found in Google Sheets\")\r\n    \r\n    # Date range filter\r\n    if st.session_state.data_loaded and not st.session_state.df.empty:\r\n        st.sidebar.header(\"üìÖ Date Range\")\r\n        \r\n        df = st.session_state.df\r\n        \r\n        if 'publish_date' in df.columns:\r\n            # Ensure publish_date is datetime\r\n            df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')\r\n            \r\n            # Drop rows with invalid dates if any\r\n            df = df.dropna(subset=['publish_date'])\r\n            \r\n            if not df.empty:\r\n                min_date = df['publish_date'].min().date()\r\n                max_date = df['publish_date'].max().date()\r\n                \r\n                date_range = st.sidebar.date_input(\r\n                    \"Select date range\",\r\n                    value=(min_date, max_date),\r\n                    min_value=min_date,\r\n                    max_value=max_date\r\n                )\r\n            \r\n            if len(date_range) == 2:\r\n                mask = (df['publish_date'].dt.date >= date_range[0]) & (df['publish_date'].dt.date <= date_range[1])\r\n                df = df[mask]\r\n                \r\n                # Also filter comments if they exist\r\n                if not st.session_state.df_comments.empty:\r\n                    df_c = st.session_state.df_comments\r\n                    if 'date' in df_c.columns:\r\n                        mask_c = (df_c['date'].dt.date >= date_range[0]) & (df_c['date'].dt.date <= date_range[1])\r\n                        st.session_state.df_comments_filtered = df_c[mask_c]\r\n                    else:\r\n                        st.session_state.df_comments_filtered = df_c\r\n                else:\r\n                    st.session_state.df_comments_filtered = pd.DataFrame()\r\n    \r\n    # Main content\r\n    if st.session_state.data_loaded and not st.session_state.df.empty:\r\n        df = st.session_state.df\r\n        analyzer = get_analyzer()\r\n        \r\n        # Ensure analytics are calculated (for both fresh scrapes and loaded data)\r\n        if 'engagement_rate' not in df.columns:\r\n            df = analyzer.calculate_engagement_rate(df)\r\n        if 'sentiment' not in df.columns or 'sentiment_score' not in df.columns:\r\n            df = analyzer.add_sentiment_analysis(df, method='vader')\r\n        \r\n        # Update session state with enriched data\r\n        st.session_state.df = df\r\n        \r\n        # Key metrics\r\n        col1, col2, col3, col4, col5 = st.columns(5)\r\n        \r\n        with col1:\r\n            st.metric(\"Total Videos\", f\"{len(df):,}\")\r\n        with col2:\r\n            st.metric(\"Total Views\", f\"{df['views'].sum():,.0f}\")\r\n        with col3:\r\n            st.metric(\"Total Likes\", f\"{df['likes'].sum():,.0f}\")\r\n        with col4:\r\n            st.metric(\"Total Shares\", f\"{df['shares'].sum():,.0f}\")\r\n        with col5:\r\n            # Check if saves exist in the dataset\r\n            saves_sum = df['saves'].sum() if 'saves' in df.columns else 0\r\n            st.metric(\"Total Saves\", f\"{saves_sum:,.0f}\")\r\n        \r\n        # New row for averages\r\n        acol1, acol2, acol3 = st.columns(3)\r\n        with acol1:\r\n            st.metric(\"Avg Engagement\", f\"{df['engagement_rate'].mean():.2f}%\")\r\n        with acol2:\r\n            st.metric(\"Total Comments\", f\"{df['comments'].sum():,.0f}\")\r\n        with acol3:\r\n            # Comment data count\r\n            c_count = len(st.session_state.df_comments_filtered) if not st.session_state.df_comments_filtered.empty else 0\r\n            st.metric(\"Scraped Comments\", f\"{c_count:,}\")\r\n        \r\n        st.divider()\r\n        \r\n        # Top Content Gallery\r\n        st.subheader(\"üî• Top Trending Videos\")\r\n        top_videos = df.sort_values('views', ascending=False).head(4)\r\n        \r\n        vid_cols = st.columns(4)\r\n        for idx, (_, row) in enumerate(top_videos.iterrows()):\r\n            with vid_cols[idx]:\r\n                st.markdown(f\"**@{row['author']}**\")\r\n                # Clean caption for display\r\n                caption_preview = (row['caption'][:50] + '...') if len(row['caption']) > 50 else row['caption']\r\n                st.caption(f\"{caption_preview}\")\r\n                \r\n                # Metric Badge\r\n                st.markdown(f\"\"\"\r\n                <div style=\"background: rgba(255,255,255,0.1); padding: 5px; border-radius: 5px; font-size: 0.8em; margin-bottom: 5px;\">\r\n                    üëÅÔ∏è {row['views']:,} | ‚ù§Ô∏è {row['likes']:,} | üí¨ {row['comments']:,} | Mood: {row['sentiment']}\r\n                </div>\r\n                \"\"\", unsafe_allow_html=True)\r\n                \r\n                st.markdown(f\"[üé• Watch Video]({row['video_url']})\")\r\n\r\n        st.divider()\r\n\r\n        # Advanced Interactive Charts\r\n        col1, col2 = st.columns([2, 1])\r\n        \r\n        with col1:\r\n            st.subheader(\"üó∫Ô∏è Engagement Landscape\")\r\n            # Bubble Chart: X=Time, Y=Views, Size=Likes+Comments, Color=Sentiment\r\n            \r\n            # Normalize size for bubbles\r\n            df['total_engagement'] = df['likes'] + df['comments'] + df['shares']\r\n            \r\n            fig = px.scatter(\r\n                df,\r\n                x='publish_date',\r\n                y='views',\r\n                size='total_engagement',\r\n                color='sentiment',\r\n                hover_data=['author', 'caption', 'video_url'],\r\n                title='Content Performance Timeline (Bubble Size = Engagement)',\r\n                color_discrete_map={'positive': '#00CC96', 'neutral': '#AB63FA', 'negative': '#EF553B'},\r\n                render_mode='webgl'\r\n            )\r\n            \r\n            fig.update_layout(\r\n                plot_bgcolor='rgba(0,0,0,0)',\r\n                paper_bgcolor='rgba(0,0,0,0)',\r\n                xaxis=dict(showgrid=False, title=\"Publish Date\"),\r\n                yaxis=dict(showgrid=True, title=\"Views\"),\r\n                hovermode='closest'\r\n            )\r\n            st.plotly_chart(fig, use_container_width=True)\r\n            \r\n        with col2:\r\n            st.subheader(\"üéØ Sentiment Distribution\")\r\n            sentiment_counts = df['sentiment'].value_counts().reset_index()\r\n            sentiment_counts.columns = ['sentiment', 'count']\r\n            \r\n            fig_pie = px.pie(\r\n                sentiment_counts, \r\n                values='count', \r\n                names='sentiment',\r\n                color='sentiment',\r\n                color_discrete_map={'positive': '#00CC96', 'neutral': '#AB63FA', 'negative': '#EF553B'},\r\n                hole=0.4\r\n            )\r\n            fig_pie.update_layout(\r\n                paper_bgcolor='rgba(0,0,0,0)',\r\n                legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1, xanchor=\"center\", x=0.5)\r\n            )\r\n            st.plotly_chart(fig_pie, use_container_width=True)\r\n\r\n\r\n        st.subheader(\"‚ö° Engagement Breakdown\")\r\n        col1, col2 = st.columns([2, 1])\r\n        with col1:\r\n            # Stacked Bar of interactions\r\n            time_agg = analyzer.aggregate_by_time(df, freq='D')\r\n            if not time_agg.empty:\r\n                fig_bar = go.Figure(data=[\r\n                    go.Bar(name='Likes', x=time_agg['publish_date'], y=time_agg['likes'], marker_color='#667eea'),\r\n                    go.Bar(name='Comments', x=time_agg['publish_date'], y=time_agg['comments'], marker_color='#764ba2'),\r\n                    go.Bar(name='Shares', x=time_agg['publish_date'], y=time_agg['shares'], marker_color='#f093fb')\r\n                ])\r\n                if 'saves' in time_agg.columns:\r\n                     fig_bar.add_trace(go.Bar(name='Saves', x=time_agg['publish_date'], y=time_agg['saves'], marker_color='#ffcc00'))\r\n\r\n                fig_bar.update_layout(\r\n                    barmode='stack',\r\n                    plot_bgcolor='rgba(0,0,0,0)',\r\n                    paper_bgcolor='rgba(0,0,0,0)',\r\n                    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\r\n                )\r\n                st.plotly_chart(fig_bar, use_container_width=True)\r\n        \r\n        with col2:\r\n             # Additional stats or info\r\n             st.info(\"The chart on the left shows daily engagement totals. You can hover over bars to see breakdown by type.\")\r\n\r\n        # Word cloud & Authors\r\n        col1, col2 = st.columns(2)\r\n        with col1:\r\n            st.subheader(\"‚òÅÔ∏è Trending Keywords\")\r\n            all_captions = ' '.join(df['caption'].dropna().astype(str))\r\n            if all_captions:\r\n                wordcloud_fig = create_wordcloud(all_captions)\r\n                if wordcloud_fig:\r\n                    st.pyplot(wordcloud_fig, use_container_width=True)\r\n                    \r\n        with col2:\r\n             st.subheader(\"üèÜ Influencer Leaderboard\")\r\n             author_stats = df.groupby('author').agg({\r\n                'video_id': 'count',\r\n                'views': 'sum',\r\n                'engagement_rate': 'mean'\r\n            }).round(2).sort_values('views', ascending=False).head(8)\r\n             \r\n             # Display as a styled dataframe with bars\r\n             st.dataframe(\r\n                 author_stats,\r\n                 column_config={\r\n                     \"engagement_rate\": st.column_config.ProgressColumn(\r\n                         \"Engagement %\",\r\n                         format=\"%.2f%%\",\r\n                         min_value=0,\r\n                         max_value=100,\r\n                     ),\r\n                     \"views\": st.column_config.NumberColumn(\r\n                         \"Total Views\",\r\n                         format=\"%d ‚≠ê\"\r\n                     )\r\n                 },\r\n                 use_container_width=True\r\n             )\r\n\r\n        # Interactive Data Table with Links\r\n        st.subheader(\"üìã Detailed Content Log\")\r\n        st.markdown(\"Click any URL to open the video/comment.\")\r\n        \r\n        # Prepare display copy\r\n        display_df = df.copy()\r\n        \r\n        # Configure columns for clickable links\r\n        st.dataframe(\r\n            display_df[[\r\n                'publish_date', 'author', 'caption', 'video_url', \r\n                'views', 'likes', 'comments', 'engagement_rate', 'sentiment'\r\n            ]],\r\n            column_config={\r\n                \"video_url\": st.column_config.LinkColumn(\r\n                    \"Video Link\",\r\n                    display_text=\"Watch Video üîó\"\r\n                ),\r\n                \"author\": st.column_config.TextColumn(\"Creator\"),\r\n                \"publish_date\": st.column_config.DatetimeColumn(\"Posted\", format=\"D MMM YYYY, HH:mm\"),\r\n                \"views\": st.column_config.NumberColumn(\"Views\", format=\"%d\"),\r\n                \"engagement_rate\": st.column_config.NumberColumn(\"Eng. Rate\", format=\"%.2f%%\"),\r\n                \"sentiment\": st.column_config.TextColumn(\"Mood\")\r\n            },\r\n            hide_index=True,\r\n            use_container_width=True\r\n        )\r\n\r\n        # COMMENTS SECTION\r\n        st.divider()\r\n        st.header(\"üí¨ Detailed Comment Analysis\")\r\n        \r\n        df_c = st.session_state.df_comments_filtered\r\n        \r\n        if not df_c.empty:\r\n            ccol1, ccol2 = st.columns([1, 2])\r\n            \r\n            with ccol1:\r\n                st.subheader(\"Comment Sentiment\")\r\n                c_sentiment_counts = df_c['sentiment'].value_counts().reset_index()\r\n                c_sentiment_counts.columns = ['sentiment', 'count']\r\n                \r\n                fig_c_pie = px.pie(\r\n                    c_sentiment_counts,\r\n                    values='count',\r\n                    names='sentiment',\r\n                    color='sentiment',\r\n                    color_discrete_map={'positive': '#00CC96', 'neutral': '#AB63FA', 'negative': '#EF553B'},\r\n                    hole=0.4\r\n                )\r\n                fig_c_pie.update_layout(\r\n                    paper_bgcolor='rgba(0,0,0,0)',\r\n                    font_color='white',\r\n                    showlegend=True,\r\n                    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1, xanchor=\"center\", x=0.5)\r\n                )\r\n                st.plotly_chart(fig_c_pie, use_container_width=True)\r\n                \r\n                # Sentiment Score Distribution\r\n                fig_c_hist = px.histogram(\r\n                    df_c, \r\n                    x='sentiment_score',\r\n                    nbins=20,\r\n                    color_discrete_sequence=['#764ba2'],\r\n                    title=\"Comment Sentiment Score Distribution\"\r\n                )\r\n                fig_c_hist.update_layout(paper_bgcolor='rgba(0,0,0,0)', font_color='white')\r\n                st.plotly_chart(fig_c_hist, use_container_width=True)\r\n            \r\n            with ccol2:\r\n                st.subheader(\"Trending Comment Keywords\")\r\n                comment_text = ' '.join(df_c['text'].dropna().astype(str))\r\n                if comment_text:\r\n                    c_wordcloud = create_wordcloud(comment_text)\r\n                    if c_wordcloud:\r\n                        st.pyplot(c_wordcloud, use_container_width=True)\r\n                \r\n                st.subheader(\"Top Liked Comments\")\r\n                top_comments = df_c.sort_values('likes', ascending=False).head(10)\r\n                st.dataframe(\r\n                    top_comments[['author', 'text', 'likes', 'date', 'sentiment']],\r\n                    column_config={\r\n                        \"date\": st.column_config.DatetimeColumn(\"Date\", format=\"D MMM, HH:mm\"),\r\n                        \"likes\": st.column_config.NumberColumn(\"Likes\", format=\"%d ‚ù§Ô∏è\"),\r\n                        \"sentiment\": st.column_config.TextColumn(\"Sentiment\")\r\n                    },\r\n                    hide_index=True,\r\n                    use_container_width=True\r\n                )\r\n            \r\n            st.subheader(\"Raw Comment Feed\")\r\n            st.dataframe(\r\n                df_c[['date', 'author', 'text', 'likes', 'sentiment', 'video_id']],\r\n                column_config={\r\n                    \"date\": st.column_config.DatetimeColumn(\"Date\", format=\"D MMM YY, HH:mm\"),\r\n                    \"video_id\": st.column_config.TextColumn(\"Video ID\")\r\n                },\r\n                hide_index=True,\r\n                use_container_width=True\r\n            )\r\n        else:\r\n            st.info(\"No comment data available for the selected period. Ensure you scrape with 'Scrape Comments' enabled.\")\r\n        \r\n    else:\r\n        # Welcome screen\r\n        st.info(\"üëã Welcome! Use the sidebar to scrape TikTok data or load existing data from Google Sheets.\")\r\n        \r\n        col1, col2, col3 = st.columns(3)\r\n        \r\n        with col1:\r\n            st.markdown(\"### üîç Scrape Data\")\r\n            st.write(\"Search by hashtag or username to collect TikTok videos\")\r\n        \r\n        with col2:\r\n            st.markdown(\"### üìä Analyze\")\r\n            st.write(\"Get sentiment analysis, engagement metrics, and trends\")\r\n        \r\n        with col3:\r\n            st.markdown(\"### üíæ Store\")\r\n            st.write(\"Automatically save to Google Sheets for persistence\")\r\n    \r\n    # Footer\r\n    st.divider()\r\n    sheets = get_sheets_manager()\r\n    if sheets.get_sheet_url():\r\n        st.info(f\"üìä Data stored in: [{sheets.sheet_name}]({sheets.get_sheet_url()})\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\n</file>\n<file path=\"analysis.py\">\n\"\"\"\r\nAnalytics module for TikTok data analysis\r\n\"\"\"\r\nimport pandas as pd\r\nfrom textblob import TextBlob\r\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\r\nfrom collections import Counter\r\nimport re\r\n\r\n\r\nclass TikTokAnalyzer:\r\n    def __init__(self):\r\n        \"\"\"Initialize analyzer with sentiment tools\"\"\"\r\n        self.vader = SentimentIntensityAnalyzer()\r\n    \r\n    def calculate_engagement_rate(self, df):\r\n        \"\"\"\r\n        Calculate engagement rate for each video\r\n        Engagement Rate = (Likes + Comments + Shares) / Views * 100\r\n        \r\n        Args:\r\n            df: DataFrame with TikTok data\r\n            \r\n        Returns:\r\n            DataFrame with engagement_rate column added\r\n        \"\"\"\r\n        if df.empty:\r\n            return df\r\n        \r\n        df = df.copy()\r\n        \r\n        # Calculate engagement rate\r\n        df['engagement_rate'] = (\r\n            (df['likes'] + df['comments'] + df['shares']) / \r\n            df['views'].replace(0, 1) * 100\r\n        ).round(2)\r\n        \r\n        return df\r\n    \r\n    def analyze_sentiment_textblob(self, text):\r\n        \"\"\"\r\n        Analyze sentiment using TextBlob\r\n        \r\n        Returns:\r\n            Dictionary with polarity and subjectivity\r\n        \"\"\"\r\n        if not text or pd.isna(text):\r\n            return {'polarity': 0, 'subjectivity': 0, 'sentiment': 'neutral'}\r\n        \r\n        try:\r\n            blob = TextBlob(str(text))\r\n            polarity = blob.sentiment.polarity\r\n            \r\n            if polarity > 0.1:\r\n                sentiment = 'positive'\r\n            elif polarity < -0.1:\r\n                sentiment = 'negative'\r\n            else:\r\n                sentiment = 'neutral'\r\n            \r\n            return {\r\n                'polarity': round(polarity, 3),\r\n                'subjectivity': round(blob.sentiment.subjectivity, 3),\r\n                'sentiment': sentiment\r\n            }\r\n        except:\r\n            return {'polarity': 0, 'subjectivity': 0, 'sentiment': 'neutral'}\r\n    \r\n    def analyze_sentiment_vader(self, text):\r\n        \"\"\"\r\n        Analyze sentiment using VADER\r\n        \r\n        Returns:\r\n            Dictionary with compound score and sentiment label\r\n        \"\"\"\r\n        if not text or pd.isna(text):\r\n            return {'compound': 0, 'sentiment': 'neutral'}\r\n        \r\n        try:\r\n            scores = self.vader.polarity_scores(str(text))\r\n            compound = scores['compound']\r\n            \r\n            if compound >= 0.05:\r\n                sentiment = 'positive'\r\n            elif compound <= -0.05:\r\n                sentiment = 'negative'\r\n            else:\r\n                sentiment = 'neutral'\r\n            \r\n            return {\r\n                'compound': round(compound, 3),\r\n                'sentiment': sentiment\r\n            }\r\n        except:\r\n            return {'compound': 0, 'sentiment': 'neutral'}\r\n    \r\n    def add_sentiment_analysis(self, df, method='vader', text_column='caption'):\r\n        \"\"\"\r\n        Add sentiment analysis to DataFrame\r\n        \r\n        Args:\r\n            df: DataFrame with text column\r\n            method: 'vader' or 'textblob'\r\n            text_column: Name of column containing text to analyze\r\n            \r\n        Returns:\r\n            DataFrame with sentiment columns added\r\n        \"\"\"\r\n        if df.empty or text_column not in df.columns:\r\n            return df\r\n        \r\n        df = df.copy()\r\n        \r\n        if method == 'vader':\r\n            sentiments = df[text_column].apply(self.analyze_sentiment_vader)\r\n            df['sentiment_score'] = sentiments.apply(lambda x: x['compound'])\r\n            df['sentiment_score'] = sentiments.apply(lambda x: x['compound'])\r\n            df['sentiment'] = sentiments.apply(lambda x: x['sentiment'])\r\n        else:\r\n            sentiments = df[text_column].apply(self.analyze_sentiment_textblob)\r\n            df['sentiment_score'] = sentiments.apply(lambda x: x['polarity'])\r\n            df['sentiment'] = sentiments.apply(lambda x: x['sentiment'])\r\n        \r\n        return df\r\n    \r\n    def extract_word_frequency(self, df, top_n=20):\r\n        \"\"\"\r\n        Extract most common words from captions\r\n        \r\n        Args:\r\n            df: DataFrame with caption column\r\n            top_n: Number of top words to return\r\n            \r\n        Returns:\r\n            List of tuples (word, count)\r\n        \"\"\"\r\n        if df.empty or 'caption' not in df.columns:\r\n            return []\r\n        \r\n        # Combine all captions\r\n        all_text = ' '.join(df['caption'].dropna().astype(str))\r\n        \r\n        # Remove hashtags, mentions, URLs, and special characters\r\n        all_text = re.sub(r'#\\w+', '', all_text)\r\n        all_text = re.sub(r'@\\w+', '', all_text)\r\n        all_text = re.sub(r'http\\S+', '', all_text)\r\n        all_text = re.sub(r'[^\\w\\s]', '', all_text)\r\n        \r\n        # Convert to lowercase and split\r\n        words = all_text.lower().split()\r\n        \r\n        # Remove common stop words\r\n        stop_words = {\r\n            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\r\n            'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',\r\n            'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\r\n            'would', 'could', 'should', 'may', 'might', 'can', 'this', 'that',\r\n            'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'my',\r\n            'your', 'his', 'her', 'its', 'our', 'their'\r\n        }\r\n        \r\n        words = [w for w in words if w not in stop_words and len(w) > 2]\r\n        \r\n        # Count frequency\r\n        word_counts = Counter(words)\r\n        \r\n        return word_counts.most_common(top_n)\r\n    \r\n    def aggregate_by_time(self, df, freq='D'):\r\n        \"\"\"\r\n        Aggregate metrics by time period\r\n        \r\n        Args:\r\n            df: DataFrame with publish_date column\r\n            freq: Pandas frequency string ('H' for hour, 'D' for day, 'W' for week)\r\n            \r\n        Returns:\r\n            DataFrame aggregated by time period\r\n        \"\"\"\r\n        if df.empty or 'publish_date' not in df.columns:\r\n            return pd.DataFrame()\r\n        \r\n        df = df.copy()\r\n        \r\n        # Ensure publish_date is datetime\r\n        df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')\r\n        df = df.dropna(subset=['publish_date'])\r\n        \r\n        if df.empty:\r\n            return pd.DataFrame()\r\n        \r\n        # Set index and resample\r\n        df_time = df.set_index('publish_date')\r\n        \r\n        aggregated = df_time.resample(freq).agg({\r\n            'video_id': 'count',\r\n            'views': 'sum',\r\n            'likes': 'sum',\r\n            'comments': 'sum',\r\n            'shares': 'sum',\r\n            'saves': 'sum' if 'saves' in df_time.columns else 'max' # max is a safe fallback if column missing\r\n        }).rename(columns={'video_id': 'video_count'})\r\n        \r\n        if 'saves' not in df_time.columns:\r\n            aggregated = aggregated.drop(columns=['saves'], errors='ignore')\r\n        \r\n        return aggregated.reset_index()\r\n    \r\n    def get_top_posts(self, df, metric='engagement_rate', top_n=10):\r\n        \"\"\"\r\n        Get top performing posts by specified metric\r\n        \r\n        Args:\r\n            df: DataFrame with TikTok data\r\n            metric: Column name to sort by\r\n            top_n: Number of top posts to return\r\n            \r\n        Returns:\r\n            DataFrame with top posts\r\n        \"\"\"\r\n        if df.empty or metric not in df.columns:\r\n            return pd.DataFrame()\r\n        \r\n        return df.nlargest(top_n, metric)\r\n    \r\n    def get_sentiment_distribution(self, df):\r\n        \"\"\"\r\n        Get distribution of sentiment categories\r\n        \r\n        Returns:\r\n            Dictionary with sentiment counts\r\n        \"\"\"\r\n        if df.empty or 'sentiment' not in df.columns:\r\n            return {'positive': 0, 'neutral': 0, 'negative': 0}\r\n        \r\n        sentiment_counts = df['sentiment'].value_counts().to_dict()\r\n        \r\n        # Ensure all categories are present\r\n        return {\r\n            'positive': sentiment_counts.get('positive', 0),\r\n            'neutral': sentiment_counts.get('neutral', 0),\r\n            'negative': sentiment_counts.get('negative', 0)\r\n        }\r\n\n</file>\n\n"
  } ],
  "stream" : true,
  "stream_options" : {
    "include_usage" : true
  },
  "max_completion_tokens" : 65535,
  "user" : "237f4ef9-3a42-4850-a635-615fca689856",
  "reasoning_effort" : "disable",
  "prompt_cache_key" : "gemini-3-flash-preview237f4ef9-3a42-4850-a635-615fca689856"
}